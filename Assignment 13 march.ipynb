{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd7418e6-7177-445d-8da5-3ef3c1a632e0",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72df04c-1045-4d2a-ac54-a1fc12a32375",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANOVA) is a statistical test used to compare means between two or more groups to determine if there are significant differences among them. ANOVA makes several assumptions about the data to produce valid and reliable results. Violations of these assumptions can impact the accuracy and validity of ANOVA results. The main assumptions of ANOVA are:\n",
    "\n",
    "Independence: The data points within each group must be independent of each other. This means that the observations in one group should not be related or influenced by the observations in other groups. Violations of independence can occur when there are dependencies or repeated measurements within groups, leading to biased results.\n",
    "\n",
    "Normality: The data within each group should follow a normal distribution. The assumption of normality is necessary because ANOVA is sensitive to departures from normality, especially with small sample sizes. Violations of normality can lead to inaccurate p-values and incorrect conclusions.\n",
    "\n",
    "Homogeneity of Variance (Homoscedasticity): The variances of the data in each group should be approximately equal. Homoscedasticity ensures that the groups have similar levels of variability, and it is crucial for the ANOVA test to provide accurate results. Violations of homoscedasticity can lead to inflated Type I error rates and can affect the reliability of ANOVA results.\n",
    "\n",
    "Independent Observations: The observations in one group should be independent of the observations in other groups. In other words, the data should not be paired or matched across groups, as this can introduce bias in the results.\n",
    "\n",
    "Examples of violations that could impact the validity of ANOVA results:\n",
    "\n",
    "Outliers: The presence of extreme outliers in the data can lead to violations of normality and homoscedasticity assumptions. Outliers can distort the distribution and introduce bias into the analysis.\n",
    "\n",
    "Skewed Data: If the data within each group is strongly skewed, it may violate the assumption of normality. In such cases, transformations or non-parametric tests might be more appropriate.\n",
    "\n",
    "Unequal Variances: When the variances across groups are significantly different, the assumption of homoscedasticity is violated. This can lead to unreliable F-tests and incorrect conclusions about group differences.\n",
    "\n",
    "Dependent Observations: If the data points within each group are not independent (e.g., repeated measures or matched pairs), the independence assumption is violated, and ANOVA may not be appropriate. In such cases, repeated measures ANOVA or other methods for dependent data should be used.\n",
    "\n",
    "Small Sample Sizes: ANOVA is more sensitive to violations of assumptions with small sample sizes. In such cases, non-parametric tests or bootstrapping methods might be more suitable.\n",
    "\n",
    "Non-Normal Residuals: The residuals (i.e., the differences between observed values and predicted values) from the ANOVA model should also follow a normal distribution. If the residuals are not normally distributed, it can indicate a violation of the normality assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131be3c4-98ea-4e6a-b45f-4681d5351a4c",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9addafb5-d3c1-4eb4-96c5-ab80b0e7b7cc",
   "metadata": {},
   "source": [
    "ANOVA (Analysis of Variance) is a statistical technique used to compare means between two or more groups. There are three main types of ANOVA, each designed for specific situations:\n",
    "\n",
    "One-Way ANOVA:\n",
    "\n",
    "Situation: One-Way ANOVA is used when there is one categorical independent variable (also called a factor) with more than two levels (groups), and the dependent variable is continuous.\n",
    "Example: Suppose you want to compare the effectiveness of three different treatments (Treatment A, Treatment B, and Treatment C) on a certain outcome variable (e.g., pain relief). Each treatment is applied to a separate group of patients, and you want to determine if there are any significant differences in the mean pain relief scores among the three treatments.\n",
    "Two-Way ANOVA:\n",
    "\n",
    "Situation: Two-Way ANOVA is used when there are two categorical independent variables (factors) with more than two levels each, and the dependent variable is continuous.\n",
    "Example: Consider a study investigating the effect of both gender and treatment type on a response variable (e.g., test scores). You have male and female participants, and each participant is randomly assigned to one of three treatments (Treatment A, Treatment B, or Treatment C). Two-Way ANOVA allows you to determine if there are significant main effects for gender and treatment, as well as any interaction between the two factors.\n",
    "Repeated Measures ANOVA:\n",
    "\n",
    "Situation: Repeated Measures ANOVA is used when you have a single group of participants and measure them multiple times under different conditions.\n",
    "Example: Suppose you want to examine the effect of three different time points (e.g., before treatment, after one week of treatment, and after two weeks of treatment) on a continuous outcome variable (e.g., blood pressure). Each participant's blood pressure is measured at the three time points, and you want to determine if there are any significant changes over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df883ad0-227f-4ede-bca7-b03b6baf2e07",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c62fe50-e9e0-4276-a33a-4204698ca14e",
   "metadata": {},
   "source": [
    "The partitioning of variance in ANOVA refers to the decomposition of the total variation observed in the data into different sources or components of variation. ANOVA breaks down the total variance of the dependent variable into various components attributed to different factors, such as treatment groups or independent variables, error, and any interactions between factors. Understanding the partitioning of variance is crucial in ANOVA because it helps researchers to:\n",
    "\n",
    "Identify Sources of Variation: By partitioning the total variance into different components, ANOVA allows researchers to identify which factors are contributing significantly to the variation in the dependent variable. This helps in understanding the relative importance of each factor and its impact on the outcome.\n",
    "\n",
    "Test Hypotheses: ANOVA enables researchers to test hypotheses related to the effects of various factors. By comparing the variation explained by different factors with the variation attributed to random error, researchers can determine if there are statistically significant differences among the groups or conditions being studied.\n",
    "\n",
    "Assess Group Differences: Understanding the partitioning of variance allows researchers to determine if there are significant differences between different treatment groups or levels of the independent variable. This information is vital in drawing conclusions about the effectiveness of interventions or comparing different experimental conditions.\n",
    "\n",
    "Examine Interactions: ANOVA can identify whether there are interactions between different factors. An interaction occurs when the effect of one factor on the dependent variable is influenced by another factor. Understanding interactions helps in understanding complex relationships between variables and how they jointly affect the outcome.\n",
    "\n",
    "Guide Further Analysis: The partitioning of variance provides insights into which factors are most important and deserve further investigation. It can guide researchers in focusing on specific aspects of the data that are of interest and relevance for deeper analysis.\n",
    "\n",
    "Improve Experimental Design: By understanding the sources of variation, researchers can optimize their experimental designs to increase the power of their studies and minimize potential confounding factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb5c5b8-2499-451c-89ff-c25de3dddffc",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2def5a7c-d90c-41d1-820f-10ccbd1fd6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 450.93333333333334\n",
      "Explained Sum of Squares (SSE): 416.1333333333334\n",
      "Residual Sum of Squares (SSR): 34.799999999999955\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def one_way_anova_sums_of_squares(groups):\n",
    "    \"\"\"\n",
    "    Calculate the total sum of squares (SST), explained sum of squares (SSE),\n",
    "    and residual sum of squares (SSR) for a one-way ANOVA.\n",
    "\n",
    "    Parameters:\n",
    "        groups (list of arrays): A list containing arrays of data for each group.\n",
    "\n",
    "    Returns:\n",
    "        SST (float): Total sum of squares.\n",
    "        SSE (float): Explained sum of squares.\n",
    "        SSR (float): Residual sum of squares.\n",
    "    \"\"\"\n",
    "    # Combine all group data into a single array\n",
    "    all_data = np.concatenate(groups)\n",
    "\n",
    "    # Calculate the grand mean\n",
    "    grand_mean = np.mean(all_data)\n",
    "\n",
    "    # Calculate the total sum of squares (SST)\n",
    "    SST = np.sum((all_data - grand_mean)**2)\n",
    "\n",
    "    # Calculate the explained sum of squares (SSE)\n",
    "    SSE = 0\n",
    "    for group in groups:\n",
    "        group_mean = np.mean(group)\n",
    "        SSE += len(group) * (group_mean - grand_mean)**2\n",
    "\n",
    "    # Calculate the residual sum of squares (SSR)\n",
    "    SSR = SST - SSE\n",
    "\n",
    "    return SST, SSE, SSR\n",
    "\n",
    "# Example data for three groups (Group A, Group B, and Group C)\n",
    "group_a = np.array([10, 12, 15, 13, 11])\n",
    "group_b = np.array([18, 20, 21, 22, 19])\n",
    "group_c = np.array([25, 23, 27, 24, 26])\n",
    "\n",
    "# Calculate the sums of squares for the one-way ANOVA\n",
    "SST, SSE, SSR = one_way_anova_sums_of_squares([group_a, group_b, group_c])\n",
    "\n",
    "# Display the results\n",
    "print(\"Total Sum of Squares (SST):\", SST)\n",
    "print(\"Explained Sum of Squares (SSE):\", SSE)\n",
    "print(\"Residual Sum of Squares (SSR):\", SSR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97107c49-edab-46dd-94e4-90a6fdfd964a",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfbf1fb4-9ee3-475b-8a35-1c1f8541d11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect of Factor 1: -4.0\n",
      "Main Effect of Factor 2: -1.0\n",
      "Interaction Effect: [[ 0.  2.]\n",
      " [ 4.  6.]\n",
      " [ 8. 10.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def two_way_anova_effects(data, factor1_levels, factor2_levels):\n",
    "    \"\"\"\n",
    "    Calculate the main effects and interaction effect for a two-way ANOVA.\n",
    "\n",
    "    Parameters:\n",
    "        data (2D array): The data matrix with rows as observations and columns as variables.\n",
    "        factor1_levels (array): An array containing the levels of the first independent variable.\n",
    "        factor2_levels (array): An array containing the levels of the second independent variable.\n",
    "\n",
    "    Returns:\n",
    "        main_effect_1 (array): Main effect of the first independent variable.\n",
    "        main_effect_2 (array): Main effect of the second independent variable.\n",
    "        interaction_effect (2D array): Interaction effect between the two independent variables.\n",
    "    \"\"\"\n",
    "    # Calculate the overall mean of the dependent variable\n",
    "    overall_mean = np.mean(data)\n",
    "\n",
    "    # Calculate the means for each combination of levels of the two independent variables (cell means)\n",
    "    cell_means = []\n",
    "    for level1 in factor1_levels:\n",
    "        for level2 in factor2_levels:\n",
    "            cell_data = data[(factor1 == level1) & (factor2 == level2)]\n",
    "            cell_means.append(np.mean(cell_data))\n",
    "\n",
    "    # Calculate the main effect for each independent variable\n",
    "    main_effect_1 = np.mean(cell_means[:len(factor2_levels)]) - overall_mean\n",
    "    main_effect_2 = np.mean(cell_means[::len(factor2_levels)]) - overall_mean\n",
    "\n",
    "    # Calculate the interaction effect\n",
    "    interaction_effect = np.array(cell_means).reshape(len(factor1_levels), len(factor2_levels)) - \\\n",
    "                         (main_effect_1 + main_effect_2 + overall_mean)\n",
    "\n",
    "    return main_effect_1, main_effect_2, interaction_effect\n",
    "\n",
    "# Example data for a two-way ANOVA with two independent variables (factor1 and factor2) and one dependent variable (response)\n",
    "factor1 = np.array([1, 1, 2, 2, 3, 3])\n",
    "factor2 = np.array([1, 2, 1, 2, 1, 2])\n",
    "response = np.array([10, 12, 14, 16, 18, 20])\n",
    "\n",
    "# Combine data into a 2D array (rows are observations, columns are variables)\n",
    "data = np.column_stack((factor1, factor2, response))\n",
    "\n",
    "# Levels of the two independent variables\n",
    "factor1_levels = np.unique(factor1)\n",
    "factor2_levels = np.unique(factor2)\n",
    "\n",
    "# Calculate the main effects and interaction effect\n",
    "main_effect_1, main_effect_2, interaction_effect = two_way_anova_effects(data[:, 2], factor1_levels, factor2_levels)\n",
    "\n",
    "# Display the results\n",
    "print(\"Main Effect of Factor 1:\", main_effect_1)\n",
    "print(\"Main Effect of Factor 2:\", main_effect_2)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e518716-60dc-4070-ba6c-e8eabe3e1868",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44732d77-6857-4d45-8141-469e016ced28",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, the F-statistic is used to test whether there are significant differences in the means of two or more groups. The associated p-value indicates the probability of obtaining the observed F-statistic (or a more extreme value) under the assumption that there are no true differences among the group means.\n",
    "\n",
    "In this case, you obtained an F-statistic of 5.23 and a p-value of 0.02. To interpret these results:\n",
    "\n",
    "Statistical Significance: The p-value (0.02) is less than the chosen significance level (commonly set at 0.05), indicating that the observed F-statistic is statistically significant. This means that there is strong evidence to reject the null hypothesis, which states that there are no significant differences between the group means.\n",
    "\n",
    "Conclusions about Group Differences: Since the null hypothesis is rejected, we can conclude that there are significant differences between at least two of the groups. However, the ANOVA itself does not specify which groups are different from each other; additional post hoc tests (e.g., Tukey's test or Bonferroni correction) would be needed to identify the specific group differences.\n",
    "\n",
    "Magnitude of the Effect: The F-statistic (5.23) provides a measure of the magnitude of the differences between the groups. A larger F-statistic suggests a larger effect size, meaning that the group means are more distinct from each other.\n",
    "\n",
    "Practical Significance: While the result is statistically significant, it is also important to consider the practical or real-world significance of the differences. Even though the groups might be different, the size of the difference might not be meaningful or practically relevant in certain contexts. This aspect requires additional judgment based on the specific application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150b9006-3808-4f4d-a0c2-b50f9e525cdd",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f8d75a-ee49-44dc-9224-2ea39a64cd2d",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA is an important consideration to ensure accurate and unbiased results. Several methods can be used to deal with missing data, and the choice of method can have different consequences on the analysis and interpretations. Here are some common approaches to handle missing data in a repeated measures ANOVA:\n",
    "\n",
    "Complete Case Analysis (Listwise Deletion):\n",
    "\n",
    "This method involves excluding any participant who has missing data on any of the variables used in the analysis.\n",
    "Consequences: While it is straightforward, it can lead to a reduction in sample size, potentially decreasing the power of the analysis and may introduce bias if the missing data are not missing completely at random (MCAR).\n",
    "Mean Imputation:\n",
    "\n",
    "This method involves replacing the missing value with the mean of the observed values for that variable.\n",
    "Consequences: Mean imputation can artificially reduce the variability in the data, leading to underestimation of standard errors and potentially invalid results. It may also introduce bias if the missing data are not MCAR.\n",
    "Last Observation Carried Forward (LOCF):\n",
    "\n",
    "This method involves using the last observed value for a participant to fill in missing data for subsequent time points.\n",
    "Consequences: LOCF can introduce bias if the participants' values are not stable over time. It may not be suitable for all data types, especially when there is substantial variation between time points.\n",
    "Multiple Imputation:\n",
    "\n",
    "This method involves creating multiple plausible imputed datasets to account for uncertainty in the imputation process. The analysis is then conducted on each imputed dataset, and results are combined to obtain valid statistical inferences.\n",
    "Consequences: Multiple imputation is considered a more robust approach, as it properly accounts for uncertainty in the imputation process and provides more accurate estimates of standard errors. However, it can be computationally intensive and requires assumptions about the missing data mechanism.\n",
    "Maximum Likelihood Estimation (MLE):\n",
    "\n",
    "MLE uses all available information to estimate model parameters, including data from participants with missing values. It involves optimizing the likelihood function to estimate the parameters that best fit the observed data.\n",
    "Consequences: MLE can provide efficient and unbiased estimates of model parameters under certain assumptions. However, it may require a larger sample size and can be sensitive to assumptions about the distribution of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c084e3ba-2075-4045-8c17-0431d7ae6f66",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4cbfd1-0fcb-497a-a939-6729fb20317d",
   "metadata": {},
   "source": [
    "Post-hoc tests are used in ANOVA to identify specific group differences when the overall ANOVA test indicates a significant difference among the groups. Since ANOVA only tells us that there is at least one significant difference between groups, post-hoc tests help pinpoint which specific group pairs are significantly different from each other. Some common post-hoc tests include:\n",
    "\n",
    "Tukey's Honestly Significant Difference (HSD):\n",
    "\n",
    "Tukey's HSD test is one of the most widely used post-hoc tests. It controls the family-wise error rate, making it suitable for multiple comparisons. It compares all possible pairs of group means and reports which pairs have significant differences.\n",
    "Use: Tukey's HSD is appropriate when you have a relatively large number of groups and want to compare all possible pairs of means in a single step.\n",
    "Bonferroni Correction:\n",
    "\n",
    "Bonferroni correction is a simple method that adjusts the alpha level for each comparison to control the family-wise error rate. The alpha level is divided by the number of comparisons, making it more conservative.\n",
    "Use: Bonferroni correction is useful when you want to perform multiple pairwise comparisons, but you need a more stringent control of the overall Type I error rate.\n",
    "Dunnett's Test:\n",
    "\n",
    "Dunnett's test compares each group mean to a control group mean. It is useful when you have one control group and several treatment groups and you are primarily interested in comparing the treatment groups to the control group.\n",
    "Use: Dunnett's test is appropriate when you have a control group and want to determine if the treatment groups differ significantly from the control group.\n",
    "Scheffe's Method:\n",
    "\n",
    "Scheffe's method is a conservative post-hoc test that can be used for any number of comparisons. It accounts for all possible contrasts and does not make specific assumptions about the nature of the comparisons.\n",
    "Use: Scheffe's method is a robust option when you need to perform multiple comparisons and are concerned about making Type I errors.\n",
    "Example Situation:\n",
    "Suppose you conducted an experiment to test the effects of different doses of a new drug on pain relief. You have four groups: Placebo, Low Dose, Medium Dose, and High Dose. After running a one-way ANOVA, you find that there is a significant difference among the four groups in terms of pain relief. Now, you want to identify which specific group pairs differ significantly from each other.\n",
    "\n",
    "In this situation, you would use a post-hoc test, such as Tukey's HSD or Scheffe's method, to compare the means of all possible pairs of groups. These post-hoc tests will tell you which specific dose levels show statistically significant differences in pain relief compared to each other. This information can help you identify which dose(s) of the drug provide more effective pain relief than others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a621a889-1a6b-467a-b22e-edc8c48dc210",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae43dbcc-fec3-445f-bb92-c552ea076c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 485.58494684620865\n",
      "p-value: 5.8194568578718994e-64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Example data for weight loss in each diet group (A, B, and C)\n",
    "diet_A = np.array([4.5, 3.7, 5.1, 4.8, 5.5, 3.9, 4.2, 3.5, 4.9, 5.2, 4.7, 4.3, 5.3, 4.6, 3.8, 4.1, 4.4, 3.6, 4.0, 5.0,\n",
    "                   3.4, 3.2, 3.0, 3.3, 4.8, 5.4, 3.3, 4.9, 4.5, 5.1, 4.2, 5.3, 4.7, 4.3, 5.3, 4.6, 3.8, 4.1, 4.4, 3.6,\n",
    "                   4.0, 5.0, 3.4, 3.2, 3.0, 3.3, 4.8, 5.4])\n",
    "diet_B = np.array([2.8, 3.1, 2.6, 2.4, 3.0, 2.9, 2.7, 3.2, 2.8, 2.6, 2.7, 3.1, 2.5, 2.9, 2.4, 3.0, 2.7, 2.8, 2.6, 2.9,\n",
    "                   3.3, 2.8, 3.2, 2.8, 2.6, 2.7, 3.1, 2.5, 2.9, 2.4, 3.0, 2.7, 2.8, 2.6, 2.9, 3.3, 2.8, 3.2, 2.8, 2.6,\n",
    "                   2.7, 3.1, 2.5, 2.9, 2.4, 3.0, 2.7, 2.8])\n",
    "diet_C = np.array([1.3, 1.2, 1.5, 1.6, 1.4, 1.2, 1.5, 1.3, 1.6, 1.7, 1.4, 1.2, 1.3, 1.2, 1.5, 1.6, 1.4, 1.2, 1.5, 1.3,\n",
    "                   1.6, 1.7, 1.4, 1.2, 1.3, 1.2, 1.5, 1.6, 1.4, 1.2, 1.3, 1.2, 1.5, 1.6, 1.4, 1.2, 1.3, 1.2, 1.5, 1.3,\n",
    "                   1.6, 1.7, 1.4, 1.2, 1.3, 1.2, 1.5, 1.6])\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Report the results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebefa72-7974-4c9e-8b51-93c73436ebd0",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aec8423-6346-4405-b8d6-994388cfb11b",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    " Example data for task completion time\n",
    "software_program = np.repeat(['A', 'B', 'C'], 30)\n",
    "employee_experience = np.tile(['Novice', 'Experienced'], 45)\n",
    "task_completion_time = np.array([10, 15, 12, 13, 11, 14, 18, 20, 17, 16, 19, 22, 25, 23, 21, 24, 28, 26, 30, 29,\n",
    "                                 31, 33, 32, 35, 34, 36, 38, 40, 37, 39, 42, 45, 43, 41, 44, 48, 46, 50, 49,\n",
    "                                 51, 53, 52, 55, 54, 56, 58, 60, 57, 59, 62, 65, 63, 61, 64, 68, 66, 70, 69])\n",
    "\n",
    " Create a DataFrame to store the data\n",
    "data = pd.DataFrame({'Software_Program': software_program,\n",
    "                     'Employee_Experience': employee_experience,\n",
    "                     'Task_Completion_Time': task_completion_time})\n",
    "\n",
    " Convert Employee_Experience to a categorical variable\n",
    "data['Employee_Experience'] = pd.Categorical(data['Employee_Experience'])\n",
    "\n",
    " Fit the two-way ANOVA model\n",
    "model = ols('Task_Completion_Time ~ C(Software_Program) + C(Employee_Experience) + C(Software_Program):C(Employee_Experience)', data=data).fit()\n",
    " Perform the two-way ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    " Report the results\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cbad96-af92-4491-983f-ae9d3c5b586a",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c497a47-9ad3-4ebb-ab83-30a72c18c8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -16.194475641359865\n",
      "p-value: 3.913701802439871e-41\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Example data for test scores of the control group and experimental group\n",
    "control_group_scores = np.array([85, 78, 92, 70, 88, 75, 90, 81, 85, 79, 80, 82, 76, 84, 87, 71, 83, 88, 79, 75,\n",
    "                                 89, 86, 78, 80, 82, 77, 90, 85, 84, 82, 75, 89, 87, 73, 81, 85, 89, 79, 88,\n",
    "                                 86, 82, 84, 77, 81, 85, 79, 83, 82, 86, 90, 81, 85, 79, 78, 87, 86, 82, 81,\n",
    "                                 79, 85, 89, 77, 83, 88, 82, 86, 75, 81, 84, 80, 82, 79, 85, 76, 88, 85, 83,\n",
    "                                 87, 78, 86, 89, 80, 82, 85, 81, 85, 84, 77, 89, 85, 78, 82, 86, 81, 79, 83,\n",
    "                                 88, 79, 85, 89, 82, 86, 75, 81, 84, 80, 82, 79, 85, 76, 88, 85, 83, 87, 78,\n",
    "                                 86, 89, 80, 82, 85, 81])\n",
    "\n",
    "experimental_group_scores = np.array([90, 88, 95, 84, 92, 87, 94, 89, 91, 86, 85, 90, 88, 93, 90, 85, 91, 95, 87, 85,\n",
    "                                      92, 94, 85, 88, 89, 86, 93, 90, 92, 87, 85, 91, 93, 86, 89, 94, 92, 88, 90,\n",
    "                                      88, 91, 93, 86, 89, 94, 92, 88, 90, 88, 91, 93, 86, 89, 94, 92, 88, 90, 88,\n",
    "                                      91, 93, 86, 89, 94, 92, 88, 90, 88, 91, 93, 86, 89, 94, 92, 88, 90, 88, 91,\n",
    "                                      93, 86, 89, 94, 92, 88, 90, 88, 91, 93, 86, 89, 94, 92, 88, 90, 88, 91, 93,\n",
    "                                      86, 89, 94, 92, 88, 90, 88, 91, 93, 86, 89, 94, 92, 88, 90, 88, 91, 93, 86,\n",
    "                                      89, 94, 92, 88, 90, 88, 91, 93, 86, 89, 94, 92, 88, 90, 88, 91, 93, 86, 89,\n",
    "                                      94, 92, 88, 90])\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = ttest_ind(control_group_scores, experimental_group_scores)\n",
    "\n",
    "# Report the results\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aab219c-b7e7-4e89-80a4-6684aac2bab2",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea59eb9c-2f53-4aac-a8ac-e2f771664e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           sum_sq    df           F        PR(>F)\n",
      "C(Store)  18500.0   2.0  370.852535  2.622332e-43\n",
      "Residual   2170.0  87.0         NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data for daily sales of three retail stores (Store A, Store B, and Store C)\n",
    "store_A_sales = np.array([100, 95, 105, 110, 98, 102, 100, 95, 105, 110, 98, 102, 100, 95, 105, 110, 98, 102, 100,\n",
    "                          95, 105, 110, 98, 102, 100, 95, 105, 110, 98, 102])\n",
    "store_B_sales = np.array([120, 115, 125, 130, 118, 122, 120, 115, 125, 130, 118, 122, 120, 115, 125, 130, 118, 122, 120,\n",
    "                          115, 125, 130, 118, 122, 120, 115, 125, 130, 118, 122])\n",
    "store_C_sales = np.array([80, 85, 90, 95, 88, 82, 80, 85, 90, 95, 88, 82, 80, 85, 90, 95, 88, 82, 80, 85, 90, 95, 88,\n",
    "                          82, 80, 85, 90, 95, 88, 82])\n",
    "\n",
    "# Combine the data into a DataFrame\n",
    "data = pd.DataFrame({'Store_A': store_A_sales,\n",
    "                     'Store_B': store_B_sales,\n",
    "                     'Store_C': store_C_sales})\n",
    "\n",
    "# Convert the data to long format for repeated measures ANOVA\n",
    "data_long = pd.melt(data, value_vars=['Store_A', 'Store_B', 'Store_C'], var_name='Store', value_name='Sales')\n",
    "\n",
    "# Fit the repeated measures ANOVA model\n",
    "model = ols('Sales ~ C(Store)', data=data_long).fit()\n",
    "\n",
    "# Perform the repeated measures ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Report the results\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6193afb-4d64-4891-abbb-889b52ce53eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
